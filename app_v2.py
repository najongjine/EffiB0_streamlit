import json
import numpy as np
import h5py
from PIL import Image
import streamlit as st
from pathlib import Path

import tensorflow as tf
from tensorflow.keras.models import load_model, Model
from tensorflow.keras.preprocessing import image as kimage
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input
from tensorflow.keras import layers

IMG_H, IMG_W = 224, 224
MODEL_FILE = "EfficientNetB0.h5"
LABEL_FILE = "EfficientNetB0.json"

st.set_page_config(page_title="EfficientNetB0 ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°", page_icon="ğŸ§ ", layout="centered")
st.title("ğŸ§  EfficientNetB0 ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° (í˜¸í™˜ ë¡œë”)")
st.caption("ëª¨ë¸/ë¼ë²¨ ë²„ì „ ì°¨ì´Â·í—¤ë“œ êµ¬ì¡° ì°¨ì´ë¥¼ ìµœëŒ€í•œ í¡ìˆ˜í•˜ë„ë¡ ì„¤ê³„í•œ ë¡œë”ì…ë‹ˆë‹¤.")

def _load_labels(p: Path):
    with open(p, "r", encoding="utf-8") as f:
        labels = json.load(f)
    if isinstance(labels, dict):
        try:
            labels = [labels[str(i)] for i in range(len(labels))]
        except Exception:
            labels = list(labels.values())
    return labels

def _inspect_input_channels_from_h5(h5_path: Path) -> int | None:
    try:
        with h5py.File(str(h5_path), "r") as f:
            # keras saverëŠ” ê°€ì¤‘ì¹˜ ê²½ë¡œê°€ êµ¬í˜„/ë²„ì „ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ íƒìƒ‰ ì‹œë„
            for k in f.keys():
                # stem_conv/kernel ì´ë¦„ í›„ë³´ë“¤ì„ ìŠ¤ìº”
                def walk(g):
                    for name, item in g.items():
                        if isinstance(item, h5py.Dataset) and name.endswith("kernel:0"):
                            # ì»¤ë„ shape = (kh, kw, Cin, Cout)
                            shp = item.shape
                            if len(shp) == 4 and shp[-1] == 32 and shp[0] == 3 and shp[1] == 3:
                                return shp[2]  # Cin
                        elif isinstance(item, h5py.Group):
                            cin = walk(item)
                            if cin is not None:
                                return cin
                cin = walk(f[k]) if isinstance(f[k], h5py.Group) else None
                if cin is not None:
                    return int(cin)
    except Exception:
        pass
    return None

def _build_backbone(channels: int):
    # í•™ìŠµ ì‹œ include_top=False ì˜€ì„ ê°€ëŠ¥ì„± ë†’ìŒ â†’ backboneë§Œ êµ¬ì„±
    backbone = EfficientNetB0(
        weights=None,
        include_top=False,
        input_shape=(IMG_H, IMG_W, channels)
    )
    x = layers.GlobalAveragePooling2D(name="gap")(backbone.output)
    # ë¶„ë¥˜ í—¤ë“œëŠ” ë‚˜ì¤‘ì— í´ë˜ìŠ¤ ìˆ˜ë¥¼ ì•Œê³  ë¶™ì„
    return backbone, x

def _attach_head(x, num_classes: int):
    out = layers.Dense(num_classes, activation="softmax", name="pred")(x)
    return out

@st.cache_resource(show_spinner=True)
def load_model_and_labels():
    mpath = Path(MODEL_FILE)
    lpath = Path(LABEL_FILE)

    if not lpath.exists():
        raise FileNotFoundError(f"ë¼ë²¨ íŒŒì¼ ì—†ìŒ: {lpath.resolve()}")
    class_names = _load_labels(lpath)
    num_classes = len(class_names)
    if num_classes < 2:
        st.warning("ë¼ë²¨ ìˆ˜ê°€ 2 ë¯¸ë§Œì…ë‹ˆë‹¤. ë¼ë²¨ JSONì„ í™•ì¸í•˜ì„¸ìš”.")

    if not mpath.exists():
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {mpath.resolve()}")

    # A) ëª¨ë¸ ì „ì²´ ë¡œë”© (í•™ìŠµ ë‹¹ì‹œ SavedModel/h5 full modelì¸ ê²½ìš°)
    try:
        model = load_model(str(mpath), compile=False)
        return model, class_names
    except Exception as eA:
        st.info(f"ì§ì ‘ load_model ì‹¤íŒ¨ â†’ ë°±ë³¸ ì¬êµ¬ì„± í›„ by_name ë¡œë”© ì‹œë„. ì—ëŸ¬: {eA}")

    # B) H5ì—ì„œ stem_conv ì»¤ë„ë¡œ ì…ë ¥ ì±„ë„ ì¶”ì •
    in_ch = _inspect_input_channels_from_h5(mpath) or 3
    st.write(f"ì¶”ì • ì…ë ¥ ì±„ë„: {in_ch}")

    # C) include_top=False ë°±ë³¸ ë§Œë“¤ê³ , by_name=True + skip_mismatch=Trueë¡œ ìµœëŒ€í•œ ì£¼ì…
    backbone, feat = _build_backbone(in_ch)
    try:
        backbone.load_weights(str(mpath), by_name=True, skip_mismatch=True)
        st.success("ë°±ë³¸ ê°€ì¤‘ì¹˜(by_name, skip_mismatch) ì¼ë¶€/ì „ì²´ ì£¼ì… ì„±ê³µ.")
    except Exception as eB:
        st.warning(f"ë°±ë³¸ ê°€ì¤‘ì¹˜ ì£¼ì… ì‹¤íŒ¨(ê³„ì† ì§„í–‰): {eB}")

    # D) ë¶„ë¥˜ í—¤ë“œ ë¶€ì°©
    logits = _attach_head(feat, num_classes)
    model = Model(backbone.input, logits, name="effib0_recovered")

    # (ì„ íƒ) ì¶”ë¡ ìš© compile
    model.compile(optimizer="adam", loss="sparse_categorical_crossentropy")

    return model, class_names

# ====== UI ======
try:
    model, class_names = load_model_and_labels()
    st.success("âœ… ëª¨ë¸/ë¼ë²¨ ë¡œë”© ì™„ë£Œ!")
except Exception as e:
    st.error(f"ëª¨ë¸/ë¼ë²¨ ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()

uploaded = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ (JPG/PNG)", type=["jpg", "jpeg", "png"])

if uploaded:
    in_channels = model.input_shape[-1]
    img = Image.open(uploaded)
    img = img.convert("L" if in_channels == 1 else "RGB")

    st.image(img, caption="ì—…ë¡œë“œ ì´ë¯¸ì§€", use_container_width=True)

    img_resized = img.resize((IMG_W, IMG_H))
    img_arr = kimage.img_to_array(img_resized)
    img_arr = preprocess_input(img_arr)
    img_batch = np.expand_dims(img_arr, axis=0)

    with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
        probs = model.predict(img_batch, verbose=0)[0]

    top = int(np.argmax(probs))
    pred = class_names[top] if top < len(class_names) else f"Class {top}"

    st.subheader("ğŸ”® ì˜ˆì¸¡ ê²°ê³¼")
    st.write(f"**Predicted:** {pred}")

    try:
        import pandas as pd
        k = min(len(probs), len(class_names))
        df = pd.DataFrame({"class": class_names[:k], "probability": probs[:k]}).sort_values("probability", ascending=False)
        st.dataframe(df.reset_index(drop=True), use_container_width=True)
        st.bar_chart(df.set_index("class"))
    except Exception:
        st.write("í´ë˜ìŠ¤ë³„ í™•ë¥ :")
        for i in np.argsort(-probs[:len(class_names)]):
            st.write(f"- {class_names[i]}: {probs[i]:.4f}")
else:
    st.info("ì˜¤ë¥¸ìª½ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”. ëª¨ë¸/ë¼ë²¨ì€ ì´ íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ë‘ì„¸ìš”.")
